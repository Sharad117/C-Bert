{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=torch.load('/kaggle/input/vector-pooler-128/vector_pooler_128.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder= encoder.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('/kaggle/input/suicide-watch/Suicide_Detection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.iloc[:90000]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class']= data['class'].map({'suicide':1.0,'non-suicide':0.0})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.value_counts('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data= pd.read_csv('/kaggle/input/suicide-data-paired-for-contrastive-learning/test.csv').iloc[:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data['class']=val_data['class'].map({'suicide':1.0,'non-suicide':0.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_data.shape)\n",
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inference(Dataset):\n",
    "    def __init__(self,data, tokenizer,max_length=128):\n",
    "        self.data=data\n",
    "        self.text_column='text'\n",
    "        self.tokenizer=tokenizer\n",
    "        self.max_length=max_length\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        text=self.data.iloc[idx][self.text_column]\n",
    "        label=self.data.iloc[idx]['class']\n",
    "        inputs=self.tokenizer(text,padding='max_length',truncation=True,max_length=self.max_length,return_tensors='pt')\n",
    "          \n",
    "        return inputs,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= inference(data,tokenizer)\n",
    "dataloader= DataLoader(dataset,batch_size =64,shuffle=True)\n",
    "val_dataset=inference(val_data,tokenizer)\n",
    "val_loader=DataLoader(val_dataset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.fc1 = nn.Linear(256, 128)  \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 16)\n",
    "        self.fc5 = nn.Linear(16, 1)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            latent = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden = F.relu(self.fc1(latent))\n",
    "        hidden = F.relu(self.fc2(hidden))\n",
    "        hidden = self.drop(hidden)\n",
    "        hidden = F.relu(self.fc3(hidden))\n",
    "        hidden = F.relu(self.fc4(hidden))\n",
    "        out = torch.sigmoid(self.fc5(hidden))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier= Classifier(encoder)\n",
    "classifier.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion= nn.BCELoss()\n",
    "opt= torch.optim.Adam(classifier.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_losses = []\n",
    "valid_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    classifier.train()\n",
    "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch}/{epochs}\"):\n",
    "        inputs, label = batch\n",
    "        \n",
    "        input_ids, attention_mask = inputs['input_ids'].squeeze(1).to('cuda'), inputs['attention_mask'].squeeze(1).to('cuda')\n",
    "        label = label.float().to('cuda').type(torch.float32)  \n",
    "\n",
    "        opt.zero_grad()\n",
    "        output = classifier(input_ids, attention_mask).squeeze(1)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_loss += loss.item() * input_ids.size(0)  \n",
    "\n",
    "    classifier.eval()\n",
    "    for batch in val_loader:\n",
    "        inputs, target = batch\n",
    "        \n",
    "        input_ids, attention_mask = inputs['input_ids'].squeeze(1).to('cuda'), inputs['attention_mask'].squeeze(1).to('cuda')\n",
    "        target = target.float().to('cuda').type(torch.float32)  \n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = classifier(input_ids, attention_mask).squeeze(1)\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss += loss.item() * input_ids.size(0) \n",
    "\n",
    "    train_loss = train_loss / len(dataloader.dataset)\n",
    "    valid_loss = valid_loss / len(val_loader.dataset)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    print(f'\\tTraining Loss: {train_loss:.6f} \\tValidation Loss: {valid_loss:.6f}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifier,'/kaggle/working/classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, n_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, n_epochs + 1), valid_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
